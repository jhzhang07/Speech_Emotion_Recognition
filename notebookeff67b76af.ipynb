{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## CAS739 Workshop 3: NSGA-II","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"markdown","source":"To explore NSGA-II, we'll use the [PyMOO](https://pymoo.org/algorithms/moo/nsga2.html) library and a Multi-Objective Travelling Salesman Problem. For the different objectives, we'll construct random distance matrices, but we could imagine, for example, that one objective is travel time between two points and a second objective is travel cost. We want to minimize both objectives, choosing a route from the Pareto front of quick and low-cost travel.","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":"!pip install pymoo","metadata":{"execution":{"iopub.status.busy":"2023-09-27T05:14:17.115318Z","iopub.execute_input":"2023-09-27T05:14:17.115742Z","iopub.status.idle":"2023-09-27T05:14:37.659715Z","shell.execute_reply.started":"2023-09-27T05:14:17.115707Z","shell.execute_reply":"2023-09-27T05:14:37.658461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"slideshow":{"slide_type":"fragment"},"execution":{"iopub.status.busy":"2023-09-27T05:17:46.732202Z","iopub.execute_input":"2023-09-27T05:17:46.732735Z","iopub.status.idle":"2023-09-27T05:17:46.741583Z","shell.execute_reply.started":"2023-09-27T05:17:46.732696Z","shell.execute_reply":"2023-09-27T05:17:46.740046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First, we define the Multi-Objective Travelling Salesman Problem using the `ElementwiseProblem` class from `pymoo`. We'll define it to take any number of cities and objectives, returning a fitness of the total distance from each objective for the given individual. We specify a constraint on the order to ensure we're visiting each city once, but we'll also define the same operators as in the GA notebook to make sure all individuals meet this constraint.","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":"from pymoo.core.problem import ElementwiseProblem\n\nclass MOTSP(ElementwiseProblem):\n    \n    def __init__(self, n_cities, n_obj):\n        # lower bound\n        xl = np.zeros(n_cities)\n        # upper bound\n        xu = (n_cities-1) * np.ones(n_cities)\n        \n        self.n_cities = n_cities\n        # Each objective is represented as an n_cities x n_cities matrix\n        # in which cell [i,j] represents an abstract \"cost\" from i -> j.\n        self.objectives = []\n        for i in range(n_obj):\n            # random symmetric matrix\n            obj = np.random.rand(n_cities, n_cities)\n            obj = np.tril(obj) + np.tril(obj, -1).T\n            obj[np.diag_indices(n_cities)] = 0\n            self.objectives.append(obj)\n        \n        super().__init__(n_var=n_cities, n_obj=n_obj, n_constr=1,\n                        xl=xl, xu=xu)\n        \n    def total_cost(self, x, obj):\n        cost = 0\n        for i in range(1, len(x)):\n            cost += self.objectives[obj][x[i-1], x[i]]\n        return cost\n    \n    def _evaluate(self, x, out, *args, **kwargs):\n        # fitness based on each distance matrix\n        fits = np.zeros(len(self.objectives))\n        for i in range(len(self.objectives)):\n            fits[i] = self.total_cost(x, i)\n        \n        # check that x conains all cities\n        # constraints return negative if met\n        c = -np.sum(np.arange(self.n_cities) != np.sort(x))\n        \n        # return by modifying out\n        out[\"F\"] = np.column_stack(fits)\n        out[\"G\"] = np.array([c])","metadata":{"slideshow":{"slide_type":"slide"},"execution":{"iopub.status.busy":"2023-09-27T05:44:00.620406Z","iopub.execute_input":"2023-09-27T05:44:00.620922Z","iopub.status.idle":"2023-09-27T05:44:00.667395Z","shell.execute_reply.started":"2023-09-27T05:44:00.620845Z","shell.execute_reply":"2023-09-27T05:44:00.666296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, we define NSGA2, its hyperparameters and operators. We'll use the same operators as before. Note that `pymoo` allows for generating fewer offspring than the initial population size and that it can check for duplicates. We'll use this second feature.","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":"from pymoo.algorithms.moo.nsga2 import NSGA2\nfrom pymoo.operators.crossover.erx import EdgeRecombinationCrossover\nfrom pymoo.operators.sampling.rnd import PermutationRandomSampling\nfrom pymoo.operators.mutation.inversion import InversionMutation\n\nalgorithm = NSGA2(\n    pop_size=100,\n    n_offsprings=100,\n    sampling=PermutationRandomSampling(),\n    crossover=EdgeRecombinationCrossover(),\n    mutation=InversionMutation(),\n    eliminate_duplicates=True\n)","metadata":{"slideshow":{"slide_type":"slide"},"execution":{"iopub.status.busy":"2023-09-27T05:44:03.393940Z","iopub.execute_input":"2023-09-27T05:44:03.394322Z","iopub.status.idle":"2023-09-27T05:44:03.430442Z","shell.execute_reply.started":"2023-09-27T05:44:03.394290Z","shell.execute_reply":"2023-09-27T05:44:03.429250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To start, let's define a 20-city problem with 2 objectives. As mentioned, these could be total travel time and total travel cost. We want to minimize both objectives. Note the use of `seed=1` in the call to `minimize`: this optimization is deterministic (we can run it multiple times and get the same result).<br>\nSee <a href=\"https://pymoo.org/interface/display.html\">pymoo documentation</a> for a description of the printouts.","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":"from pymoo.optimize import minimize\n\nproblem = MOTSP(20, 2)\nres = minimize(problem,\n               algorithm,\n               (\"n_gen\", 100),\n               seed=1,\n               save_history=True,\n               verbose=True)","metadata":{"slideshow":{"slide_type":"slide"},"execution":{"iopub.status.busy":"2023-09-27T05:44:05.397032Z","iopub.execute_input":"2023-09-27T05:44:05.397465Z","iopub.status.idle":"2023-09-27T05:44:18.026260Z","shell.execute_reply.started":"2023-09-27T05:44:05.397431Z","shell.execute_reply":"2023-09-27T05:44:18.024944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `res` object returned from the search contains the results, including the final Pareto front.","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":"from pymoo.visualization.scatter import Scatter\nplot = Scatter(tight_layout=True)\nplot.add(res.F, s=10)\nplot.show();","metadata":{"slideshow":{"slide_type":"fragment"},"execution":{"iopub.status.busy":"2023-09-27T05:45:06.616139Z","iopub.execute_input":"2023-09-27T05:45:06.616576Z","iopub.status.idle":"2023-09-27T05:45:07.208568Z","shell.execute_reply.started":"2023-09-27T05:45:06.616545Z","shell.execute_reply":"2023-09-27T05:45:07.207385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-success\">\n    <h3>Exercise 1</h3>\n\nLook at the [visualization](http://pymoo.org/visualization/index.html) options in pymoo and visualize the population. What plot makes most sense to you to present the full population of possible solutions? What about when the number of objectives increases, ie to 3? What about presenting a single solution? \nWhat is the best you can do on the 3 objective problem?\n</div>","metadata":{"slideshow":{"slide_type":"fragment"}}},{"cell_type":"code","source":"for i, ind in enumerate(result_pop):\n    print(f\"Individual {i+1}:\")\n    print(f\"Fitness: {ind.F}\")\n    print(f\"Variables: {ind.X}\")\n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-09-27T06:18:22.326197Z","iopub.execute_input":"2023-09-27T06:18:22.327302Z","iopub.status.idle":"2023-09-27T06:18:22.338519Z","shell.execute_reply.started":"2023-09-27T06:18:22.327248Z","shell.execute_reply":"2023-09-27T06:18:22.337676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### For a two-objective problem, a 2D scatter plot is often the most effective and intuitive way to visualize and describe the Pareto front.\n\n### Let's now consider a three-objective problem","metadata":{}},{"cell_type":"markdown","source":"We can also visualize the convergence of each objective. We'll plot the fitness of the first individual in the Pareto front over evolution. Note that this isn't the best value for each objective independently, but rather the objective values of a single individual.","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":"n_evals = np.array([e.evaluator.n_eval for e in res.history])\nopt = np.array([e.opt[0].F for e in res.history])\n\nplt.title(\"Convergence\")\nplt.plot(n_evals, opt)\nplt.yscale(\"log\")\nplt.show()","metadata":{"slideshow":{"slide_type":"fragment"},"execution":{"iopub.status.busy":"2023-09-27T05:59:02.886396Z","iopub.execute_input":"2023-09-27T05:59:02.886854Z","iopub.status.idle":"2023-09-27T05:59:03.366988Z","shell.execute_reply.started":"2023-09-27T05:59:02.886815Z","shell.execute_reply":"2023-09-27T05:59:03.365676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As the number of dimensions grows, visualizing the convergence across all objectives becomes difficult. One recently proposed metric known as the \"running metric\" evaluates non-dominated sets from each generation relative to previously recorded sets. This gives an idea of how much the Pareto front has moved in any generation. For visualizing this running metric, each ND set is normalized by the final ND set after a certain number of generations. The difference between intervals then gives an idea if the algorithm is converging.","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"markdown","source":"<img src=\"https://github.com/d9w/evolution/raw/master/imgs/running_metric.png\">\n\nBlank, Julian, and Kalyanmoy Deb. \"A running performance metric and termination criterion for evaluating evolutionary multi-and many-objective optimization algorithms.\" Proc. IEEE World Congr. Comput. Intell.(WCCI). 2020.\n\nhttps://www.egr.msu.edu/~kdeb/papers/c2020003.pdf","metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":"from pymoo.util.running_metric import RunningMetricAnimation\n\nrunning = RunningMetricAnimation(delta_gen=20,\n                        n_plots=5,\n                        key_press=False,\n                        do_show=True)\n\nfor algorithm in res.history:\n    running.update(algorithm)","metadata":{"slideshow":{"slide_type":"slide"},"execution":{"iopub.status.busy":"2023-09-27T06:01:46.354214Z","iopub.execute_input":"2023-09-27T06:01:46.354719Z","iopub.status.idle":"2023-09-27T06:01:49.663798Z","shell.execute_reply.started":"2023-09-27T06:01:46.354682Z","shell.execute_reply":"2023-09-27T06:01:49.662455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-success\">\n    <h3>Exercise 2</h3>\n\nIncrease the number of objectives and observe the convergence of NSGA-II. Roughly, how much does each objective change convergence speed?\n</div>","metadata":{"slideshow":{"slide_type":"slide"}}}]}